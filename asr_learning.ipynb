{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Copy of open_stt_rnnt_modified_learning_on_full.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNzRVs5TwpWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for uploading big files to google drive\n",
        "\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.discovery import build\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "def save_file_to_drive(name, path):\n",
        "  file_metadata = {'name': name, 'mimeType': 'application/octet-stream'}\n",
        "  media = MediaFileUpload(path, mimetype='application/octet-stream', resumable=True)\n",
        "  created = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "  return created"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkMp9V83ZhjS",
        "colab_type": "code",
        "outputId": "dddc84c5-8f4e-43e7-8ba5-e8f2b458d456",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# for downloading files from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "mXfSHrgfGCT7",
        "colab_type": "code",
        "outputId": "70ea5c3b-680c-491b-ac8e-a4afb4bf3381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# RNN-T loss\n",
        "!pip install warp-rnnt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting warp-rnnt\n",
            "  Downloading https://files.pythonhosted.org/packages/86/6d/1389db3abbeaaed0279516878275b7c8f536c70323376bfd46a6e95e4040/warp_rnnt-0.1.0.tar.gz\n",
            "Collecting pybind11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/4d/ae1c4d8e8b139afa9682054dd42df3b0e3b5c1731287933021b9fd7e9cc4/pybind11-2.4.3-py2.py3-none-any.whl (150kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from warp-rnnt) (1.17.3)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from warp-rnnt) (1.3.0+cu100)\n",
            "Building wheels for collected packages: warp-rnnt\n",
            "  Building wheel for warp-rnnt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for warp-rnnt: filename=warp_rnnt-0.1.0-cp36-cp36m-linux_x86_64.whl size=1403375 sha256=d9d4e34c25cf2bad55f6404b4ace8ad7a872c6287a877c6f2323f2cedaa74058\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/4d/6b/004a7f35a7c506bb6f82900efb961d345d87ae9bfa06e72bb9\n",
            "Successfully built warp-rnnt\n",
            "Installing collected packages: pybind11, warp-rnnt\n",
            "Successfully installed pybind11-2.4.3 warp-rnnt-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_apWvX0NfRLW",
        "colab_type": "code",
        "outputId": "7eb1c198-58e1-47c0-c6b3-8b964e182a17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "!pip3 install python_speech_features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python_speech_features\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-cp36-none-any.whl size=5889 sha256=8b549a2c0d58b0309080138f72e638fa56377fffd9b88b97e7fc1b2bb9b0a3ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features\n",
            "Successfully installed python-speech-features-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lznXArmrc1yG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p data/datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zBY0tCvr83Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validation descriptions\n",
        "!cp -Rv \"/content/drive/My Drive/val.txt\" ./"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlM2qQfXOfEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validation mfcc features\n",
        "!cp -Rv \"/content/drive/My Drive/val.tar.gz\" ./"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO1tPGaA-acy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train mfcc features\n",
        "!cp -Rv \"/content/drive/My Drive/train_part_8a.tar.gz\" ./"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuPvG1hGsNAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xf  val.tar.gz -C /"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPka6cm1WpgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xf  /content/train_part_8a.tar.gz -C ./"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W4wjBonr3ID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp -R '/content/drive/My Drive/check/asr' /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysssLywK-7t_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5Nh3HveGZVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %cd /content/asr/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPIev6kUrMMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train annotation in diffent sizes \n",
        "\n",
        "!cp -Rv \"/content/drive/My Drive/train.txt\" /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5vnhpUnSqVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sed -n '1,100000p' train.txt > train_100000.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Mre8O1wqLNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sed -n '1,100000p' ../train.txt > ../train_100000.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jBQ0wS1ASMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sed -n '1,200000p' ../train.txt > ../train_200000.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K8ZKGsotpYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sed -n '1,400000p' ../train.txt > ../train_400000.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Wx03abYd7q5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sed -n '1,50000p' ../train.txt > ../train_50000.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xObX8QOLQFAF",
        "colab_type": "code",
        "outputId": "61089f44-23c2-4d64-8f6d-25bf43c8b925",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# loading model from previous iteration\n",
        "\n",
        "!cp -Rv \"/content/drive/My Drive/model_lm2_4e5_samp_0_ep\" ../"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'/content/drive/My Drive/model_lm2_4e5_samp_0_ep' -> '../model_lm2_4e5_samp_0_ep'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ryef1htXJNIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import log_softmax\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "\n",
        "def decrease_dim(x, layer, dim=1):\n",
        "    if type(layer) != nn.modules.conv.Conv2d:\n",
        "        return x\n",
        "    p = layer.padding[dim]\n",
        "    d = layer.dilation[dim]\n",
        "    f = layer.kernel_size[dim]\n",
        "    s = layer.stride[dim]\n",
        "    x = (x + 2 * p - d * (f - 1) - 1) // s + 1\n",
        "    return x\n",
        "\n",
        "\n",
        "def is_time_decrease(layer):\n",
        "    return decrease_dim(100, layer) != 100\n",
        "\n",
        "\n",
        "class BatchNorm1d(nn.BatchNorm1d):\n",
        "\n",
        "    def forward(self, x):\n",
        "        shape = list(x.size())\n",
        "        x = x.view(-1, self.num_features)\n",
        "        x = super().forward(x)\n",
        "        shape = shape[:-1] + [self.num_features]\n",
        "        x = x.view(shape)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MaskConv(nn.Module):\n",
        "\n",
        "    def __init__(self, layers):\n",
        "        \"\"\"\n",
        "        Erase padding of the output based on the given lengths.\n",
        "        Input needs to be in the shape of (NxCxDxT)\n",
        "        :param layers: The sequential module containing the conv stack.\n",
        "        \"\"\"\n",
        "        super(MaskConv, self).__init__()\n",
        "        self.layers = layers\n",
        "\n",
        "    def output_time(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = decrease_dim(x, layer, dim=1)\n",
        "        return x\n",
        "\n",
        "    def output_dim(self, dim):\n",
        "        channels = 0\n",
        "        for layer in self.layers:\n",
        "            dim = decrease_dim(dim, layer, dim=0)\n",
        "            if type(layer) == nn.modules.conv.Conv2d:\n",
        "                channels = layer.out_channels\n",
        "        return dim * channels\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        \"\"\"\n",
        "        :param x: The input of size NxCxDxT\n",
        "        :param lengths: The actual length of each sequence in the batch\n",
        "        :return: Masked output from the module\n",
        "        \"\"\"\n",
        "\n",
        "        mask = None\n",
        "\n",
        "        for layer in self.layers:\n",
        "\n",
        "            x = layer(x)\n",
        "\n",
        "            if is_time_decrease(layer):\n",
        "\n",
        "                lengths = decrease_dim(lengths, layer)\n",
        "\n",
        "                n, c, d, t = x.size()\n",
        "\n",
        "                mask = torch.zeros((n, 1, 1, t), dtype=torch.bool, device=x.device)\n",
        "\n",
        "                for i, length in enumerate(lengths):\n",
        "                    start = length.item()\n",
        "                    length = t - start\n",
        "                    if length > 0:\n",
        "                        mask[i].narrow(2, start, length).fill_(1)\n",
        "\n",
        "            if mask is not None:\n",
        "                x = x.masked_fill(mask, 0)\n",
        "\n",
        "        n, c, d, t = x.size()\n",
        "        x = x.view(n, c * d, t)\n",
        "        x = x.transpose(1, 2).transpose(0, 1).contiguous()  # T x N x H\n",
        "\n",
        "        return x, lengths\n",
        "\n",
        "\n",
        "class AcousticModel(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, prj_size, output_size, n_layers=1, dropout=0, checkpoint=''):\n",
        "        super(AcousticModel, self).__init__()\n",
        "        self.conv = MaskConv(nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=(21, 11), stride=(2, 2), padding=(10, 5), bias=False),\n",
        "            nn.BatchNorm2d(32), nn.ReLU(inplace=True), nn.Dropout(dropout),\n",
        "            nn.Conv2d(32, 32, kernel_size=(11, 11), stride=(2, 1), padding=(5, 5), bias=False),\n",
        "            nn.BatchNorm2d(32), nn.ReLU(inplace=True), nn.Dropout(dropout)\n",
        "        ))\n",
        "        input_size = self.conv.output_dim(input_size)\n",
        "        self.rnn = nn.GRU(input_size, hidden_size, n_layers,\n",
        "                          dropout=dropout if n_layers > 1 else 0,\n",
        "                          bidirectional=True)\n",
        "        self.prj = nn.Sequential(nn.Dropout(dropout),\n",
        "                                 nn.Linear(hidden_size, prj_size, bias=False))\n",
        "        self.fc = nn.Sequential(BatchNorm1d(prj_size), nn.ReLU(inplace=True),\n",
        "                                nn.Linear(prj_size, output_size))\n",
        "        if len(checkpoint):\n",
        "            print(checkpoint)\n",
        "            self.load_state_dict(torch.load(checkpoint, map_location='cpu'))\n",
        "\n",
        "    def features(self, x, lengths):\n",
        "        # Apply 2d convolutions\n",
        "        x, lengths = self.conv(x, lengths)\n",
        "        # Pack padded batch of sequences for RNN module\n",
        "        x = pack_padded_sequence(x, lengths)\n",
        "        # Forward pass through GRU\n",
        "        x, _ = self.rnn(x)\n",
        "        # Unpack padding\n",
        "        x, _ = pad_packed_sequence(x)\n",
        "        # Sum bidirectional GRU outputs\n",
        "        x = x[:, :, :self.rnn.hidden_size] + x[:, :, self.rnn.hidden_size:]\n",
        "        x = self.prj(x)\n",
        "        return x, lengths\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        x, lengths = self.features(x, lengths)\n",
        "        x = self.fc(x)  # T x N x H\n",
        "        return x, lengths\n",
        "\n",
        "\n",
        "class LanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, emb_size, hidden_size, prj_size, vocab_size, n_layers=1, dropout=0, blank=0, checkpoint=''):\n",
        "        super(LanguageModel, self).__init__()\n",
        "        # The gradient for blank input is always zero.\n",
        "        self.emb = nn.Embedding(vocab_size, emb_size, padding_idx=blank)\n",
        "        self.rnn = nn.LSTM(emb_size, hidden_size, num_layers=n_layers,\n",
        "                           dropout=dropout if n_layers > 1 else 0)\n",
        "        self.prj = nn.Sequential(nn.Dropout(dropout),\n",
        "                                 nn.Linear(hidden_size, prj_size, bias=False))\n",
        "        self.fc = nn.Sequential(BatchNorm1d(prj_size), nn.ReLU(inplace=True),\n",
        "                                nn.Linear(prj_size, vocab_size))\n",
        "        if len(checkpoint):\n",
        "            print(checkpoint)\n",
        "            self.load_state_dict(torch.load(checkpoint, map_location='cpu'))\n",
        "\n",
        "    def features(self, x, lengths):\n",
        "        init = torch.zeros((1, x.shape[1]), device=x.device).long()\n",
        "        x = torch.cat([init, x.long()])\n",
        "        x = self.emb(x)\n",
        "        x = pack_padded_sequence(x, lengths + 1, enforce_sorted=False)\n",
        "        x, _ = self.rnn(x)\n",
        "        x, _ = pad_packed_sequence(x)\n",
        "        x = self.prj(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        x = self.features(x, lengths)\n",
        "        x = self.fc(x)  # T x N x H\n",
        "        return x\n",
        "\n",
        "    def step_features(self, x, h=None):\n",
        "        x = self.emb(x)\n",
        "        x, h = self.rnn(x, h)\n",
        "        x = self.prj(x)\n",
        "        return x, h\n",
        "\n",
        "    def step_forward(self, x, h=None):\n",
        "        x, h = self.step_features(x, h)\n",
        "        x = self.fc(x)  # T x N x H\n",
        "        return x, h\n",
        "\n",
        "    def step_init(self, batch_size):\n",
        "        weight = next(self.rnn.parameters())\n",
        "        return (weight.new_zeros(self.rnn.num_layers, batch_size, self.rnn.hidden_size),\n",
        "                weight.new_zeros(self.rnn.num_layers, batch_size, self.rnn.hidden_size))\n",
        "\n",
        "\n",
        "class Transducer(nn.Module):\n",
        "\n",
        "    def __init__(self, emb_size, vocab_size, hidden_size, prj_size, am_layers=3, lm_layers=2, dropout=0, blank=0,\n",
        "                 am_checkpoint='', lm_checkpoint=''):\n",
        "        super(Transducer, self).__init__()\n",
        "\n",
        "        self.blank = blank\n",
        "\n",
        "        self.encoder = AcousticModel(40, hidden_size, prj_size, vocab_size, n_layers=am_layers, dropout=dropout,\n",
        "                                     checkpoint=am_checkpoint)\n",
        "        self.decoder = LanguageModel(emb_size, hidden_size, prj_size, vocab_size, n_layers=lm_layers, dropout=dropout, blank=blank,\n",
        "                                     checkpoint=lm_checkpoint)\n",
        "\n",
        "        for p in self.encoder.fc.parameters():\n",
        "            p.requires_grads = False\n",
        "        for p in self.decoder.fc.parameters():\n",
        "            p.requires_grads = False\n",
        "\n",
        "        self.fc = nn.Linear(prj_size, vocab_size)\n",
        "\n",
        "    def joint(self, x, y):\n",
        "        z = torch.tanh(x + y)\n",
        "        z = self.fc(z)\n",
        "        z = log_softmax(z, dim=-1)\n",
        "        return z\n",
        "\n",
        "    def forward(self, xs, ys, xn, yn):\n",
        "        # encoder\n",
        "        xs, xn = self.encoder.features(xs, xn)\n",
        "        xs = xs.transpose(0, 1)\n",
        "        # decoder\n",
        "        ys = self.decoder.features(ys, yn)\n",
        "        ys = ys.transpose(0, 1)\n",
        "        # align\n",
        "        n, t, x_h = xs.size()\n",
        "        n, u, y_h = ys.size()\n",
        "        x = xs.unsqueeze(dim=2).expand(torch.Size([n, t, u, x_h]))\n",
        "        y = ys.unsqueeze(dim=1).expand(torch.Size([n, t, u, y_h]))\n",
        "        # predict\n",
        "        zs = self.joint(x, y)\n",
        "        return zs, xs, xn\n",
        "\n",
        "    def greedy_decode(self, xs):\n",
        "\n",
        "        n, t, h = xs.size()\n",
        "\n",
        "        c = torch.zeros((1, n), device=xs.device).long()\n",
        "        yd, (hd, cd) = self.decoder.step_features(c)\n",
        "\n",
        "        s = torch.zeros((n, t), dtype=torch.int)\n",
        "\n",
        "        for i in range(t):\n",
        "\n",
        "            z = self.joint(xs[:, i], yd[0])\n",
        "\n",
        "            c = torch.argmax(z, dim=-1).view(1, n)\n",
        "\n",
        "            s[:, i] = c.cpu().view(n)\n",
        "\n",
        "            mask = c == self.blank\n",
        "            mask = mask.unsqueeze(-1)\n",
        "\n",
        "            yd_next, (hd_next, cd_next) = self.decoder.step_features(c, (hd, cd))\n",
        "\n",
        "            yd = torch.where(mask, yd, yd_next)\n",
        "            hd = torch.where(mask, hd, hd_next)\n",
        "            cd = torch.where(mask, cd, cd_next)\n",
        "\n",
        "        return s\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpwLs9aCoOxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/asr/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-JrBnsVXOlL",
        "colab_type": "code",
        "outputId": "b1dd4d44-db54-4ea6-a3da-c46bb464d06a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from data import Labels, AudioDataset, DataLoader, collate_fn_rnnt, BucketingSampler\n",
        "\n",
        "from tqdm import tqdm_notebook, tqdm\n",
        "\n",
        "# from model import Transducer\n",
        "from utils import AverageMeter, entropy\n",
        "\n",
        "import decoder\n",
        "\n",
        "from warp_rnnt import rnnt_loss\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "labels = Labels()\n",
        "\n",
        "model = Transducer(128, len(labels), 256, 256, am_layers=3, lm_layers=2, dropout=0.3)\n",
        "\n",
        "model.load_state_dict(torch.load(\"../model_lm2_4e5_samp_0_ep\"))\n",
        "\n",
        "train = AudioDataset('/content/train.txt', labels)\n",
        "test = AudioDataset('/content/val.txt', labels)\n",
        "\n",
        "train.filter_by_conv(model.encoder.conv)\n",
        "train.filter_by_length(5000)\n",
        "\n",
        "test.filter_by_conv(model.encoder.conv)\n",
        "test.filter_by_length(10000)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
        "\n",
        "model.cuda()\n",
        "\n",
        "sampler = BucketingSampler(train, 32)\n",
        "\n",
        "train = DataLoader(train, pin_memory=True, num_workers=2, collate_fn=collate_fn_rnnt, batch_sampler=sampler)\n",
        "test = DataLoader(test, pin_memory=True, num_workers=2, collate_fn=collate_fn_rnnt, batch_size=16)\n",
        "\n",
        "train_err = []\n",
        "train_grad = []\n",
        "\n",
        "val_err = []\n",
        "val_wer = []\n",
        "val_cer = []\n",
        "val_ent = []"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "filter     765    0.05%\n",
            "filter       0    0.00%\n",
            "filter       0    0.00%\n",
            "filter       0    0.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvn4Vi75aadK",
        "colab_type": "code",
        "outputId": "051938b5-cdf4-4008-8ade-06a0af7ba051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "print(\"Start\\n\")\n",
        "# new_epoch = epoch + 1\n",
        "new_epoch = 1\n",
        "\n",
        "for epoch in range(new_epoch, 100):\n",
        "\n",
        "    sampler.shuffle(epoch)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    err = AverageMeter('loss')\n",
        "    grd = AverageMeter('gradient')\n",
        "\n",
        "    progress = train\n",
        "    for xs, ys, xn, yn in progress:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        xs = xs.cuda(non_blocking=True)\n",
        "        ys = ys.cuda(non_blocking=True)\n",
        "        xn = xn.cuda(non_blocking=True)\n",
        "        yn = yn.cuda(non_blocking=True)\n",
        "\n",
        "        zs, xs, xn = model(xs, ys, xn, yn)\n",
        "\n",
        "        ys = ys.t().contiguous()\n",
        "\n",
        "        loss = rnnt_loss(zs, ys, xn, yn, average_frames=False, reduction=\"mean\")\n",
        "        loss.backward()\n",
        "\n",
        "        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), 100)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        err.update(loss.item())\n",
        "        grd.update(grad_norm)\n",
        "\n",
        "        \n",
        "\n",
        "        train_err.append(err)\n",
        "        train_grad.append(grd)\n",
        "\n",
        "        # progress.set_description('epoch %d %s %s' % (epoch + 1, err, grd))\n",
        "    print('epoch %d %s %s' % (epoch + 1, err, grd))\n",
        "    torch.save(model.state_dict(), \"../model_lm2_h256_full_samp_{}_ep\".format(epoch))\n",
        "    save_file_to_drive(\"model_lm2_h256_full_samp_{}_ep\".format(epoch), \n",
        "                       \"../model_lm2_h256_full_samp_{}_ep\".format(epoch))    \n",
        "    model.eval()\n",
        "\n",
        "    err = AverageMeter('loss')\n",
        "    cer = AverageMeter('cer')\n",
        "    wer = AverageMeter('wer')\n",
        "    ent = AverageMeter('ent')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        progress = test\n",
        "        for xs, ys, xn, yn in progress:\n",
        "\n",
        "            xs = xs.cuda(non_blocking=True)\n",
        "            ys = ys.cuda(non_blocking=True)\n",
        "            xn = xn.cuda(non_blocking=True)\n",
        "            yn = yn.cuda(non_blocking=True)\n",
        "\n",
        "            zs, xs, xn = model(xs, ys, xn, yn)\n",
        "\n",
        "            ys = ys.t().contiguous()\n",
        "\n",
        "            loss = rnnt_loss(zs, ys, xn, yn, average_frames=False, reduction=\"mean\")\n",
        "\n",
        "            xs = model.greedy_decode(xs)\n",
        "\n",
        "            err.update(loss.item())\n",
        "            ent.update(entropy(xs))\n",
        "\n",
        "            hypothesis = decoder.unpad(xs, xn, labels)\n",
        "            references = decoder.unpad(ys, yn, labels)\n",
        "            \n",
        "            if (epoch % 1) == 0:\n",
        "                for h, r in zip(hypothesis, references):\n",
        "                    cer.update(decoder.cer(h, r))\n",
        "                    wer.update(decoder.wer(h, r))\n",
        "\n",
        "            # progress.set_description('epoch %d %s %s %s %s' % (epoch + 1, err, cer, wer, ent))\n",
        "\n",
        "            val_err.append(err)\n",
        "            val_wer.append(wer)\n",
        "            val_cer.append(cer)\n",
        "            val_ent.append(ent)\n",
        "        print('epoch %d %s %s %s %s' % (epoch + 1, err, cer, wer, ent))\n",
        "        sys.stderr.write('\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start\n",
            "\n",
            "epoch 2 loss 22.5197±9.15 gradient 24.7021±7.04\n",
            "epoch 2 loss 17.0966±9.15 cer 0.5015±0.29 wer 0.7573±0.30 ent 1.0626±0.17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}